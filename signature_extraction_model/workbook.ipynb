{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, initializers\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "FFT_WIDTH = 80\n",
    "input_shape = (FFT_WIDTH,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@keras_export('keras.layers.MultichannelInterpolate')\n",
    "class MultichannelInterpolate(keras.layers.Layer):\n",
    "    # TODO: Allow user to specify gaussian windows\n",
    "    def __init__(self, harmonics):\n",
    "        super(MultichannelInterpolate, self).__init__(trainable=False)\n",
    "        self.harmonics = harmonics\n",
    "        self.built = False\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dummy, self.clefs, self.buckets = input_shape\n",
    "        super(MultichannelInterpolate, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        try:\n",
    "            assert inputs.shape == (None, self.clefs, self.buckets)\n",
    "        except:\n",
    "            print(\"shape=(%d, %d, %d)\" % (self.clefs, self.buckets, self.harmonics) + \" inputs.shape=%s\" % str(inputs.shape))\n",
    "            #raise\n",
    "        #inputs = tf.squeeze(inputs)\n",
    "        inputs = tf.pad(inputs, tf.constant([[0,0],[0,0],[0,1]]), \"CONSTANT\") # Add padding to prevent interpolation errors\n",
    "        inputs = inputs[..., tf.newaxis]                                # and a dummy 3rd dimension, so we can resize it like an image\n",
    "\n",
    "        from scipy.signal.windows import gaussian\n",
    "        from scipy.interpolate import interp1d\n",
    "        import numpy as np\n",
    "\n",
    "        windows = np.asarray([gaussian(2*self.buckets, 30)[self.buckets:], gaussian(self.buckets, 20), gaussian(2*self.buckets, 30)[:self.buckets]])\n",
    "        windows = np.transpose(windows)\n",
    "\n",
    "        output_list = []\n",
    "        outputs = tf.zeros((self.harmonics,self.buckets), dtype=tf.float32)\n",
    "\n",
    "        x = np.arange(0,self.buckets+1,1)\n",
    "        #interpolator = interp1d(x,inputs)\n",
    "\n",
    "        for h in range(self.harmonics):\n",
    "            clef_multiplier = tf.constant(windows[h,:], dtype=tf.float32, shape=[1,3])\n",
    "\n",
    "            interp_factor = 10.0 / (h+1)\n",
    "            load = tf.image.resize(inputs, [self.clefs,(h+1)*8], method='bilinear', antialias=True, )[...,0]\n",
    "            #load = interpolator(np.arange(0,80,interp_factor))[:,1:81]\n",
    "            load = tf.linalg.matmul(clef_multiplier, load)\n",
    "\n",
    "            try:\n",
    "                if load.shape[2] < self.buckets:\n",
    "                    load = tf.pad(load[:,0,:], tf.constant([[0,0],[0,self.buckets-load.shape[2]]]))\n",
    "                else:\n",
    "                    load = load[:,0,:self.buckets]\n",
    "            except:\n",
    "                print(\"h=%d, load=%s, clef_multiplier=%s, inputs=%s\" % (h, load, clef_multiplier, inputs))\n",
    "                raise\n",
    "\n",
    "            output_list.append(load)\n",
    "                #outputs[h,:len(load)] += load\n",
    "\n",
    "        output = tf.stack(output_list)\n",
    "        return tf.reshape(output, [-1, self.harmonics, self.buckets])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (self.harmonics, self.buckets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#calibrations = layers.Input(shape=input_shape)                      # Input is (freq, clef)\n",
    "\n",
    "calibrations = layers.Input(shape=(3, FFT_WIDTH), name=\"calibrations\")     # Have these fixed for now\n",
    "norm_calibrations = layers.LayerNormalization(axis=[1,2])(calibrations)\n",
    "x = MultichannelInterpolate(48)\n",
    "x1 = x(norm_calibrations)\n",
    "\n",
    "inputs = layers.Input(shape=(FFT_WIDTH), name=\"main_input\")                       # Input is (freq)\n",
    "norm_inputs = layers.LayerNormalization(axis=[1])(inputs)\n",
    "\n",
    "harmonic_extraction = layers.Dot(axes=(2,1))([x1, norm_inputs])                         # Output is (bucket)\n",
    "\n",
    "input_direct = layers.Dense(48, activation='relu')(inputs)\n",
    "# pool = layers.AveragePooling1D(pool_size = FFT_WIDTH,         # Output is (scaled freq)\n",
    "#         data_format=\"channels_first\")(x2)\n",
    "\n",
    "expanded = layers.Reshape((FFT_WIDTH, -1))(inputs)\n",
    "c1 = layers.Conv1D(6, 5, strides=2, padding='same')(expanded)\n",
    "c2 = layers.Conv1D(12, 5, strides=2, padding='same')(c1)\n",
    "c3 = layers.Conv1D(24, 5, strides=2, padding='same')(c2)\n",
    "c4 = layers.Conv1D(48, 5, strides=2, padding='same')(c3)\n",
    "pool = layers.MaxPooling1D(5)(c4)\n",
    "flatten_conv = layers.Flatten()(pool)\n",
    "\n",
    "merge = layers.Concatenate()([harmonic_extraction, flatten_conv, input_direct])\n",
    "flat = layers.Flatten()(merge)\n",
    "\n",
    "out = layers.Dense(48, activation='sigmoid')(flat)\n",
    "\n",
    "model = keras.Model(inputs=[calibrations, inputs], outputs=out)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=\"adam\")\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from math import floor\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "frames_filename = \"automated_guitar_nonorm_inputs.npy\"\n",
    "labels_filename = \"automated_guitar_nonorm_labels.npy\"\n",
    "frames = np.load(frames_filename)\n",
    "labels = np.load(labels_filename)\n",
    "\n",
    "assert(labels.shape[0] == frames.shape[0])\n",
    "\n",
    "# # Add other files from other instruments or playstyles\n",
    "# frames = np.concatenate((frames, np.load(\"dane_take1_inputs.npy\")), axis=0)\n",
    "# labels = np.concatenate((labels, np.load(\"dane_take1_labels.npy\")), axis=0)\n",
    "# frames = np.concatenate((frames, np.load(\"acoustic_oren_pick_take1_inputs.npy\")), axis=0)\n",
    "# labels = np.concatenate((labels, np.load(\"acoustic_oren_pick_take1_labels.npy\")), axis=0)\n",
    "\n",
    "# Shuffle it\n",
    "data_size = frames.shape[0]\n",
    "rind = list(range(data_size))\n",
    "random.shuffle(rind)\n",
    "frames = np.asarray([frames[i,:,:80] for i in rind])\n",
    "labels = np.asarray([labels[i,:48] for i in rind])\n",
    "\n",
    "frames_train, frames_test, labels_train, labels_test = train_test_split(frames, labels, test_size=0.2, random_state=1)\n",
    "frames_train, frames_val, labels_train, labels_val = train_test_split(frames_train, labels_train, test_size=0.25, random_state=1)\n",
    "\n",
    "checkpoint_path = \"training_1/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True)\n",
    "\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "model.fit([frames_train[:,1:,:], frames_train[:,0,:]], labels_train, epochs=300, validation_data=([frames_val[:,1:], frames_val[:,0]], labels_val), callbacks=[cp_callback])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "import time\n",
    "\n",
    "model.load_weights(\"training_1/cp-0087.ckpt\")\n",
    "\n",
    "guesses = 0\n",
    "false_positives = 0\n",
    "total_labels = 0\n",
    "false_negatives = 0\n",
    "i = 0\n",
    "for l, f in zip(labels_test, frames_test):\n",
    "    before = time.time()\n",
    "    inputs = np.expand_dims(f[0,:], axis=0)\n",
    "    calibs = np.expand_dims(f[1:,:], axis=0)\n",
    "    p = model.predict([calibs, inputs])[0]\n",
    "    #print(\"Time: %f\" % (time.time() - before))\n",
    "\n",
    "    # func = K.function([model.layers[5].input, model.layers[0].input], model.layers[9].output)\n",
    "    # dot_out = func([calibs, inputs])\n",
    "\n",
    "    conf = max(p)\n",
    "    pred = np.where(p > 0.8)[0]\n",
    "    correct = np.where(l == 1)[0]\n",
    "\n",
    "    false_positives += len([x for x in pred if x not in correct])\n",
    "    false_negatives += len([x for x in correct if x not in pred])\n",
    "    guesses += len(pred)\n",
    "    total_labels += len(correct)\n",
    "\n",
    "    if i < 10:\n",
    "        plt.plot(inputs[0,:])\n",
    "        plt.title(correct)\n",
    "        plt.show()\n",
    "        plt.plot(np.transpose(calibs[0]))\n",
    "        plt.show()\n",
    "        plt.bar(np.arange(len(p)), p)\n",
    "        plt.title(pred)\n",
    "        plt.show()\n",
    "    i+=1\n",
    "\n",
    "print(\"Detection rate: \" + str(1 - false_negatives / total_labels))\n",
    "print(\"False positive rate: \" + str(false_positives / guesses))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(\"tf_model\")\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Save model\n"
    }
   }
  }
 ]
}